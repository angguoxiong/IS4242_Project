{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Tuning and Cross Validation\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../../Data Files/Training Data/x_train.csv')\n",
    "x_test = pd.read_csv('../../Data Files/Training Data/x_test.csv')\n",
    "y_train = pd.read_csv('../../Data Files/Training Data/y_train.csv')\n",
    "y_test = pd.read_csv('../../Data Files/Training Data/y_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_model(num_neurons_1, num_neurons_2, activation_fn, optimizer_fn):\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(num_neurons_1, input_shape=[len(x_train.columns),], activation=activation_fn))\n",
    "    nn.add(Dense(num_neurons_2, input_shape=[len(x_train.columns),], activation=activation_fn))\n",
    "    nn.add(Dense(1, activation='linear'))\n",
    "    nn.compile(loss='mean_squared_error', optimizer=optimizer_fn, metrics=['mean_absolute_error']) \n",
    "    return nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2496/2496 [==============================] - 6s 2ms/step - loss: 4.3448 - mean_absolute_error: 1.4877\n",
      "Epoch 2/5\n",
      "2496/2496 [==============================] - 5s 2ms/step - loss: 2.3938 - mean_absolute_error: 1.1826\n",
      "Epoch 3/5\n",
      "2496/2496 [==============================] - 5s 2ms/step - loss: 2.2621 - mean_absolute_error: 1.1381\n",
      "Epoch 4/5\n",
      "2496/2496 [==============================] - 5s 2ms/step - loss: 2.2145 - mean_absolute_error: 1.1257\n",
      "Epoch 5/5\n",
      "2496/2496 [==============================] - 5s 2ms/step - loss: 2.1933 - mean_absolute_error: 1.1215\n",
      "98/98 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "nn = build_nn_model(30, 30, 'relu', 'adam')\n",
    "nn_history = nn.fit(x_train, y_train, batch_size=5, epochs=5, verbose=1)\n",
    "y_pred_nn = nn.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning for Hyperparameters with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guo Xiong\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.116 total time=   9.4s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.116 total time=   9.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.128 total time=   9.5s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.099 total time=   8.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.119 total time=   8.2s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.161 total time=   8.3s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.096 total time=   9.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.140 total time=   9.6s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.095 total time=   9.3s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.122 total time=   8.5s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.138 total time=   8.3s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.151 total time=   8.4s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.152 total time=   9.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.115 total time=   9.3s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.152 total time=   9.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.102 total time=   8.5s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.127 total time=   8.3s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.208 total time=   8.6s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.107 total time=   9.5s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.131 total time=   9.3s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.112 total time=   9.3s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.146 total time=   9.0s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.206 total time=   8.7s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.109 total time=   8.3s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.095 total time=  18.4s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.133 total time=  19.0s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.098 total time=  19.0s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.108 total time=  18.9s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.117 total time=  18.6s\n",
      "260/260 [==============================] - 1s 4ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.101 total time=  18.3s\n",
      "260/260 [==============================] - 1s 3ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.106 total time=  19.8s\n",
      "260/260 [==============================] - 1s 4ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.106 total time=  21.9s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.113 total time=  17.6s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.097 total time=  12.5s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.129 total time=  12.9s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.109 total time=  12.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.148 total time=   3.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.173 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.157 total time=   3.2s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.121 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.153 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.109 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.117 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.125 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.111 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.106 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.114 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.242 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.119 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.121 total time=   3.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.119 total time=   4.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.100 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.127 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.106 total time=   3.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.141 total time=   4.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.158 total time=   4.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.150 total time=   4.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.135 total time=   3.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.151 total time=   3.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.116 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.105 total time=   3.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.138 total time=   3.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.114 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.119 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.137 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.138 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.107 total time=   3.4s\n",
      "65/65 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.117 total time=   3.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.108 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.102 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.173 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=tanh, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.113 total time=   3.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.105 total time=  11.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.143 total time=  11.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.139 total time=  12.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.118 total time=  11.4s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.127 total time=  11.6s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.102 total time=  11.9s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.151 total time=  13.0s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.128 total time=  13.0s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.121 total time=  11.8s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.124 total time=  10.3s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.120 total time=   9.6s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.097 total time=  14.9s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.121 total time=  11.4s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.125 total time=  10.2s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.134 total time=  10.2s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.128 total time=   9.0s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.176 total time=   9.0s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.095 total time=   8.9s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.117 total time=   9.7s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.121 total time=  10.2s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.171 total time=   9.8s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.116 total time=   9.0s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.171 total time=   8.9s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.145 total time=   8.9s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.163 total time=   9.9s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.115 total time=  10.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.174 total time=  10.1s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.115 total time=   9.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.198 total time=   9.0s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.122 total time=   9.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.118 total time=  10.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.135 total time=  10.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.136 total time=  10.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.141 total time=  10.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.106 total time=   9.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.104 total time=  10.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.137 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.134 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.119 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.126 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.146 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.147 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.115 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.162 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.134 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.103 total time=   2.9s\n",
      "65/65 [==============================] - 0s 3ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.149 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.134 total time=   3.8s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.133 total time=   3.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.146 total time=   4.6s\n",
      "65/65 [==============================] - 0s 4ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.120 total time=   3.9s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.102 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.119 total time=   3.1s\n",
      "65/65 [==============================] - 0s 3ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.111 total time=   3.1s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.147 total time=   3.2s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.130 total time=   3.2s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.114 total time=   3.5s\n",
      "65/65 [==============================] - 0s 3ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.115 total time=   3.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.118 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.106 total time=   4.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.117 total time=   3.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.138 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.118 total time=   3.2s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.112 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.129 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.127 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.130 total time=   3.2s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.117 total time=   3.2s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.111 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.132 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.138 total time=   3.0s\n",
      "65/65 [==============================] - 0s 3ms/step\n",
      "[CV 3/3] END activation_fn=softplus, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.180 total time=   3.0s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.144 total time=   9.0s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.112 total time=  10.0s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.121 total time=  10.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.097 total time=   9.1s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.139 total time=   9.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.134 total time=  11.0s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.121 total time=   9.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.106 total time=   9.6s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.136 total time=   9.5s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.101 total time=   7.6s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.155 total time=   9.8s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.117 total time=   9.4s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.142 total time=  10.9s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.160 total time=  10.1s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.115 total time=   9.9s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.147 total time=   9.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.109 total time=  10.1s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.137 total time=   9.3s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.133 total time=  10.6s\n",
      "260/260 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.118 total time=  10.4s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.137 total time=  10.8s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.109 total time=   9.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.154 total time=   9.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.089 total time=   9.2s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.108 total time=  10.5s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.112 total time=   9.7s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.152 total time=  10.3s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.123 total time=   9.1s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.252 total time=   9.0s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.097 total time=   9.0s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.118 total time=   9.6s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.132 total time=  10.0s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.107 total time=  10.1s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.188 total time=   9.1s\n",
      "260/260 [==============================] - 1s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.125 total time=   9.5s\n",
      "260/260 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=16, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.098 total time=   9.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.218 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.172 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=adam;, score=-1.201 total time=   3.0s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.116 total time=   2.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.110 total time=   2.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=10, optimizer_fn=sgd;, score=-1.145 total time=   2.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.175 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.172 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=adam;, score=-1.137 total time=   2.9s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.195 total time=   2.9s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.171 total time=   2.6s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=30, optimizer_fn=sgd;, score=-1.145 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.168 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.156 total time=   3.5s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=adam;, score=-1.136 total time=   3.4s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.112 total time=   2.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.115 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=30, num_neurons_2=50, optimizer_fn=sgd;, score=-1.110 total time=   3.1s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.164 total time=   3.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.166 total time=   4.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=adam;, score=-1.153 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.140 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.112 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=10, optimizer_fn=sgd;, score=-1.105 total time=   2.7s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.166 total time=   3.0s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.134 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=adam;, score=-1.133 total time=   4.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.107 total time=   3.1s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.112 total time=   2.9s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=30, optimizer_fn=sgd;, score=-1.112 total time=   3.3s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.121 total time=   3.4s\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.131 total time=   3.2s\n",
      "65/65 [==============================] - 0s 3ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=adam;, score=-1.124 total time=   3.7s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 1/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.135 total time=   3.2s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 2/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.122 total time=   2.8s\n",
      "65/65 [==============================] - 0s 2ms/step\n",
      "[CV 3/3] END activation_fn=relu, batch_size=64, epochs=10, num_neurons_1=50, num_neurons_2=50, optimizer_fn=sgd;, score=-1.171 total time=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E4866FBE80&gt;,\n",
       "             param_grid={&#x27;activation_fn&#x27;: [&#x27;tanh&#x27;, &#x27;softplus&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [16, 64], &#x27;epochs&#x27;: [10],\n",
       "                         &#x27;num_neurons_1&#x27;: [30, 50],\n",
       "                         &#x27;num_neurons_2&#x27;: [10, 30, 50],\n",
       "                         &#x27;optimizer_fn&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E4866FBE80&gt;,\n",
       "             param_grid={&#x27;activation_fn&#x27;: [&#x27;tanh&#x27;, &#x27;softplus&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [16, 64], &#x27;epochs&#x27;: [10],\n",
       "                         &#x27;num_neurons_1&#x27;: [30, 50],\n",
       "                         &#x27;num_neurons_2&#x27;: [10, 30, 50],\n",
       "                         &#x27;optimizer_fn&#x27;: [&#x27;adam&#x27;, &#x27;sgd&#x27;]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E4866FBE80&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E4866FBE80&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001E4866FBE80>,\n",
       "             param_grid={'activation_fn': ['tanh', 'softplus', 'relu'],\n",
       "                         'batch_size': [16, 64], 'epochs': [10],\n",
       "                         'num_neurons_1': [30, 50],\n",
       "                         'num_neurons_2': [10, 30, 50],\n",
       "                         'optimizer_fn': ['adam', 'sgd']},\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasRegressor(build_fn=build_nn_model)\n",
    "\n",
    "param_grid = {'num_neurons_1': [30, 50],\n",
    "              'num_neurons_2': [10, 30, 50],\n",
    "              'activation_fn': ['tanh', 'softplus', 'relu'],\n",
    "              'optimizer_fn': ['adam', 'sgd'],\n",
    "              'batch_size': [16, 64],\n",
    "              'epochs': [10]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=skf, verbose=3)\n",
    "grid_search.fit(x_train, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 2ms/step\n",
      "mean_absolute_error = 1.12\n",
      "{'activation_fn': 'tanh', 'batch_size': 16, 'epochs': 10, 'num_neurons_1': 50, 'num_neurons_2': 50, 'optimizer_fn': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "optimal_nn = grid_search.best_estimator_\n",
    "\n",
    "y_pred = optimal_nn.predict(x_test)\n",
    "mae_after_tuning = mean_absolute_error(y_test, y_pred)\n",
    "print(\"mean_absolute_error = {:.3}\".format(mae_after_tuning)) \n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "780/780 [==============================] - 3s 3ms/step - loss: 3.2643 - mean_absolute_error: 1.3275\n",
      "Epoch 2/10\n",
      "780/780 [==============================] - 2s 3ms/step - loss: 2.2213 - mean_absolute_error: 1.1229\n",
      "Epoch 3/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1937 - mean_absolute_error: 1.1175\n",
      "Epoch 4/10\n",
      "780/780 [==============================] - 2s 3ms/step - loss: 2.1743 - mean_absolute_error: 1.1136\n",
      "Epoch 5/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1734 - mean_absolute_error: 1.1114\n",
      "Epoch 6/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1694 - mean_absolute_error: 1.1116\n",
      "Epoch 7/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1651 - mean_absolute_error: 1.1099\n",
      "Epoch 8/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1537 - mean_absolute_error: 1.1061\n",
      "Epoch 9/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1463 - mean_absolute_error: 1.1054\n",
      "Epoch 10/10\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 2.1421 - mean_absolute_error: 1.1034\n",
      "98/98 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "tuned_nn = build_nn_model(best_params['num_neurons_1'], best_params['num_neurons_2'], best_params['activation_fn'], best_params['optimizer_fn'])\n",
    "nn_history = tuned_nn.fit(x_train, y_train, batch_size=best_params['batch_size'], epochs=best_params['epochs'], verbose=1)\n",
    "y_pred_nn = tuned_nn.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model File and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../../Data Files/'\n",
    "tuned_nn.save(save_path + 'Model Files/' + 'nn.h5')\n",
    "np.savetxt(save_path + 'Predictions/' + 'neuralnetwork_output.csv', y_pred_nn, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
