{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data required in lists\n",
    "#users_list = ['ur117926588', 'ur15298231', 'ur1994077', 'ur17646017', 'ur4532636', 'ur22171966']\n",
    "users_list = ['ur3223254', 'ur66111139', 'ur63040106', 'ur84924605', 'ur4103165', 'ur59627333', 'ur98435364', 'ur65836273','ur44059846', 'ur7813355', 'ur98240498', 'ur59184301', 'ur57691865', 'ur3793011']\n",
    "user_id = []\n",
    "movie_title_list = []\n",
    "year_list = []\n",
    "review_title_list = []\n",
    "review_list = []\n",
    "error_msg = []\n",
    "review_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [20:14<00:00, 12.27s/it]\n",
      "100%|██████████| 2478/2478 [01:08<00:00, 36.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for user in range(len(users_list)):\n",
    "    print(\"Scraping for User {}\".format(user+1))\n",
    "#     driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = 'https://www.imdb.com/user/{}/reviews'.format(users_list[user])\n",
    "    time.sleep(1)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    sel = Selector(text = driver.page_source)\n",
    "    num_of_reviews = sel.css(\".header span::text\").extract_first().replace(',','').split(' ')[0]\n",
    "    more_review_pages = int(int(num_of_reviews)/25)\n",
    "    \n",
    "    user_id += [users_list[user] for i in range(int(num_of_reviews))]\n",
    "    \n",
    "    # Loading all the reviews in the single page before scraping\n",
    "    for i in tqdm(range(more_review_pages)):\n",
    "        try:\n",
    "            css_selector = 'load-more-trigger'\n",
    "            driver.find_element(By.ID, css_selector).click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "    for r in tqdm(reviews):\n",
    "        try:\n",
    "            sel2 = Selector(text = r.get_attribute('innerHTML'))\n",
    "            try:\n",
    "                movie_title = sel2.css('.lister-item-header a::text').getall()\n",
    "                title = ''\n",
    "                for t in movie_title:\n",
    "                    title += t\n",
    "                movie_title = title.strip()\n",
    "            except:\n",
    "                movie_title = np.NaN\n",
    "            try:\n",
    "                year = sel2.css('.lister-item-year.text-muted.unbold::text').extract_first().strip().replace('(','').replace(')','')\n",
    "                year = re.sub(r'[a-zA-Z\\s]+', '', year)\n",
    "            except:\n",
    "                year = np.NaN\n",
    "            try:\n",
    "                review_title = sel2.css('.title::text').extract_first().strip()\n",
    "            except:\n",
    "                review_title = np.NaN\n",
    "            try:\n",
    "                # extract all paragraphs inside review\n",
    "                review = sel2.css('.text.show-more__control::text').extract()\n",
    "                review = ' '.join(review)\n",
    "            except:\n",
    "                review = np.NaN\n",
    "                \n",
    "            movie_title_list.append(movie_title)\n",
    "            year_list.append(year)\n",
    "            review_title_list.append(review_title)\n",
    "            review_list.append(review)\n",
    "        except Exception as e:\n",
    "            error_msg.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all data in dataframe\n",
    "reviews_df = pd.DataFrame({\n",
    "    \"UserID\": user_id,\n",
    "    \"Title\": movie_title_list,\n",
    "    \"Year\": year_list,\n",
    "    \"Review_Title\": review_title_list,\n",
    "    \"Review\": review_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "reviews_df.to_csv(path_or_buf = \"users_reviews.csv\"\n",
    "                          , index = False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
