{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15adead0",
   "metadata": {},
   "source": [
    "# List of Packages required for Scrapping and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f10651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c41dee",
   "metadata": {},
   "source": [
    "## Instantiate the data required in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ff9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User List can be put into a list but we are extracting 1 by 1 for better and efficient results\n",
    "users_list = ['ur117926588']\n",
    "# ur22171966 1910 ratings\n",
    "# ur46592925 4 ratings\n",
    "# ur62522856 338 ratings\n",
    "user_id = []\n",
    "title_list = []\n",
    "description_list = []\n",
    "img_list = []\n",
    "year_list = []\n",
    "director_list = []\n",
    "star_list = []\n",
    "duration_list = []\n",
    "advisory_list = []\n",
    "genre_list = []\n",
    "vote_list = []\n",
    "movie_rating_list = []\n",
    "user_rating_list = []\n",
    "img_file_list = []\n",
    "error_msg = []\n",
    "\n",
    "record_id = 1\n",
    "record_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78cc80",
   "metadata": {},
   "source": [
    "**The code that runs through IMDB ratings website for the particular users and extract important information required for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75eee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 107.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 84.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 93.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 85.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 86.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 94.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 96.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 94.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 94.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 88.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 90.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 94.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 95.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 97.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 92.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 91.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 98.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 82/82 [00:00<00:00, 96.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages to browse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for user in range(len(users_list)):\n",
    "    print(\"Scraping for User {}\".format(user+1))\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = 'https://www.imdb.com/user/{}/ratings'.format(users_list[user])\n",
    "    time.sleep(1)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    sel = Selector(text = driver.page_source)\n",
    "    num_of_ratings = sel.css(\".lister-list-length span::text\").extract_first().replace(',','').split(' ')[0]\n",
    "    rating_pages = int(int(num_of_ratings)/100) + 1  \n",
    "    user_id += [users_list[user] for i in range(int(num_of_ratings))]\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    count = 0\n",
    "    for x in range(rating_pages):\n",
    "        sel = Selector(text = driver.page_source)\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.lister-item.mode-detail')\n",
    "        \n",
    "        # filter out the images that have a title attribute with the value \"list image\"\n",
    "        ##Get img url\n",
    "        image_tags = soup.find_all('img', {'class': 'loadlate', 'title': lambda value: value is None or value != 'list image'})\n",
    "        for img_tag in image_tags:\n",
    "            # Get the URL of the movie poster image\n",
    "            img_url = img_tag['loadlate']\n",
    "            img_list.append(img_url)\n",
    "        \n",
    "        for review in tqdm(reviews):\n",
    "            \n",
    "            try:\n",
    "                sel2 = Selector(text = review.get_attribute('innerHTML'))\n",
    "                \n",
    "                ## Get movie title\n",
    "                try:\n",
    "                    title = sel2.css('.lister-item-content a::text').extract_first().strip()\n",
    "                    episode = sel2.css('.lister-item-content a::text').getall()[1].strip()\n",
    "                    if episode != \"\":\n",
    "                        title += (\" - \" + episode)\n",
    "                except:\n",
    "                    title= np.NaN\n",
    "                    \n",
    "                ## Get movie description\n",
    "                try:\n",
    "                    advisory = sel2.css('.certificate::text').extract_first()\n",
    "                    duration = sel2.css('.runtime::text').extract_first()\n",
    "                    description = None\n",
    "                    if advisory == None and duration == None:\n",
    "                        description = sel2.css('p::text').getall()[3].strip()\n",
    "                    elif advisory == None or duration == None:\n",
    "                        description = sel2.css('p::text').getall()[5].strip()\n",
    "                    else:\n",
    "                        description = sel2.css('p::text').getall()[7].strip()\n",
    "                except:\n",
    "                    description = np.NaN\n",
    "                ## Get movie year\n",
    "                try:\n",
    "                    year = sel2.css('.lister-item-year.text-muted.unbold::text').extract_first().strip().replace('(','').replace(')','')\n",
    "                    year = re.sub(r'[a-zA-Z\\s]+', '', year)\n",
    "                except:\n",
    "                    year = np.NaN\n",
    "                ## Get directors and staff\n",
    "                try:\n",
    "                    staff = sel2.css('.text-muted a::text').getall()\n",
    "                    text = sel2.css('.text-muted.text-small::text').getall()\n",
    "                    text2 = [x.strip() for x in text]\n",
    "                    commas = text2.count(',')\n",
    "                    stars_index = text2.index(\"Stars:\")\n",
    "                    count = 0\n",
    "                    for i in range(stars_index, len(text2)-1):\n",
    "                        if text2[i] == ',':\n",
    "                            count+=1\n",
    "                    stars = staff[-(count+1):]\n",
    "                    # if directors are recorded\n",
    "                    if \"Director:\" in text2 or \"Directors:\" in text2:\n",
    "                        directors = staff[:(commas-count)+1]\n",
    "                    else:\n",
    "                        directors = \"\"\n",
    "                except:\n",
    "                    stars = np.NaN\n",
    "                    directors = np.NaN\n",
    "                ## Get movie duration\n",
    "                try:\n",
    "                    duration = duration.strip()\n",
    "                except:\n",
    "                    duration = np.NaN\n",
    "                ## Get viewer advisory\n",
    "                try:\n",
    "                    advisory = advisory.strip()\n",
    "                except:\n",
    "                    advisory = np.NaN\n",
    "                ## Get Genre\n",
    "                try:\n",
    "                    genre = sel2.css('.genre::text').extract_first().strip()\n",
    "                except:\n",
    "                    genre = np.NaN\n",
    "                ## Get votes\n",
    "                try:\n",
    "                    votes = sel2.css('.text-muted.text-small span::text').getall()[-1]\n",
    "                    votes = int(votes.replace(',','').split(' ')[0])\n",
    "                except:\n",
    "                    votes = np.NaN\n",
    "                ## Get movie rating\n",
    "                try:\n",
    "                    movie_rating = sel2.css('.ipl-rating-star__rating::text').getall()[0]\n",
    "                    movie_rating = float(movie_rating.replace(',','').split(' ')[0])\n",
    "                except:\n",
    "                    movie_rating = np.NaN\n",
    "                ## Get user rating\n",
    "                try:\n",
    "                    user_rating = sel2.css('.ipl-rating-star__rating::text').getall()[1]\n",
    "                    user_rating = int(user_rating.replace(',','').split(' ')[0])\n",
    "                except:\n",
    "                    user_rating = np.NaN\n",
    "                    \n",
    "                try:\n",
    "                    title_rename = re.sub(r'[^\\w\\s!-]|[.!?]', '', title)\n",
    "                    img_name = f\"{user_id[0]}_{record_id}.jpg\"\n",
    "                except:\n",
    "                    img_name = np.NaN\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                title_list.append(title)\n",
    "                description_list.append(description)\n",
    "                year_list.append(year)\n",
    "                director_list.append(directors)\n",
    "                star_list.append(stars)\n",
    "                duration_list.append(duration)\n",
    "                advisory_list.append(advisory)\n",
    "                genre_list.append(genre)\n",
    "                vote_list.append(votes)\n",
    "                movie_rating_list.append(movie_rating)\n",
    "                user_rating_list.append(user_rating)\n",
    "                img_file_list.append(img_name)\n",
    "                record_list.append(record_id)\n",
    "                record_id  += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg.append(e)\n",
    "        \n",
    "        try:\n",
    "            next_page_url = sel.css(\"a.flat-button.lister-page-next.next-page::attr(href)\").extract_first()\n",
    "            full_next_page_url = \"https://www.imdb.com\" + next_page_url\n",
    "            driver.get(full_next_page_url)\n",
    "            response = requests.get(full_next_page_url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        except:\n",
    "            print(\"No more pages to browse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef069371",
   "metadata": {},
   "source": [
    "**Storing the data into a dataframe and exporting it to a csv file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb4ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all data in dataframe\n",
    "rating_df = pd.DataFrame({\n",
    "     \"UserID\": user_id,\n",
    "     \"record_id\": record_list,\n",
    "     \"Title\":title_list,\n",
    "     \"Img_Path\": img_list,\n",
    "     \"Img_File_Name\": img_file_list,\n",
    "     \"Year\":year_list,\n",
    "     \"Description\":description_list,\n",
    "     \"Directors\":director_list,\n",
    "     \"Stars\": star_list,\n",
    "     \"Viewer_Advisory\": advisory_list,\n",
    "     \"Duration\": duration_list,\n",
    "     \"Genre\": genre_list,\n",
    "     \"Votes\": vote_list, \n",
    "     \"Movie_Rating\": movie_rating_list,\n",
    "     \"User_Rating\": user_rating_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6256457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "rating_df.to_csv(path_or_buf = f\"{user_id[0]}_ratings.csv\"\n",
    "                          , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8ef16",
   "metadata": {},
   "source": [
    "## Download the Images to the folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac2bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##image downloading\n",
    "def download_image(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "        img_save_path = save_path\n",
    "        img.save(img_save_path, format=\"JPEG\")\n",
    "\n",
    "        #print(f\"Image saved at {img_save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image from {url}: {e}\")\n",
    "\n",
    "# Folder for downloading\n",
    "img_folder = f\"{user_id[0]}_downloaded_images\"\n",
    "os.makedirs(img_folder, exist_ok=True)\n",
    "\n",
    "for idx, row in rating_df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    title = row['Title']\n",
    "    img_url = row['Img_Path']\n",
    "    record_id = row[\"record_id\"]\n",
    "    \n",
    "    #title = re.sub(r'[^\\w\\s!-]|[.!?]', '', title)\n",
    "\n",
    "    # File extension name\n",
    "    img_filename = f\"{user_id}_{record_id}.jpg\"\n",
    "    img_save_path = os.path.join(img_folder, img_filename)\n",
    "\n",
    "    # Download and save the image\n",
    "    download_image(img_url, img_save_path)\n",
    "    \n",
    "    #See image in python\n",
    "    #img = Image.open(img_save_path)\n",
    "    #plt.imshow(img)\n",
    "    #plt.savefig(img_save_path)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fdcc8",
   "metadata": {},
   "source": [
    "## Image Analysis using KMeans Clustering (3 main colours and Brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2285af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import pandas as pd\n",
    "import webcolors\n",
    "\n",
    "def get_main_colors(image, k=3):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.reshape(image.shape[0] * image.shape[1], 3)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(image)\n",
    "    \n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "def get_brightness(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    r, g, b = np.split(image, 3, axis=-1)\n",
    "    brightness = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return np.mean(brightness)\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to read image '{image_path}'\")\n",
    "        return None, None, None, None\n",
    "    main_colors = get_main_colors(image)\n",
    "    color1 = webcolors.rgb_to_hex(main_colors[0].astype(int))\n",
    "    color2 = webcolors.rgb_to_hex(main_colors[1].astype(int))\n",
    "    color3 = webcolors.rgb_to_hex(main_colors[2].astype(int))\n",
    "    brightness = get_brightness(image)\n",
    "    return color1, color2, color3, brightness\n",
    "\n",
    "folder_path = f'{user_id}_downloaded_images'\n",
    "image_files = os.listdir(folder_path)\n",
    "\n",
    "image_names = []\n",
    "color1_list = []\n",
    "color2_list = []\n",
    "color3_list = []\n",
    "brightness_list = []\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    color1, color2, color3, brightness = analyze_image(image_path)\n",
    "    \n",
    "    if color1 is not None and brightness is not None:\n",
    "        #print(f\"Image: {image_file}\")\n",
    "        #print(f\"Main colors: {main_colors}\")\n",
    "        #print(f\"Brightness: {brightness}\\n\")\n",
    "        image_names.append(image_file)\n",
    "        color1_list.append(color1)\n",
    "        color2_list.append(color2)\n",
    "        color3_list.append(color3)\n",
    "        brightness_list.append(brightness)\n",
    "    else:\n",
    "        print(f\"Skipping '{image_file}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0b1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Img_File_Name\": image_names,\n",
    "    \"Color1\": color1_list,\n",
    "    \"Color2\": color2_list,\n",
    "    \"Color3\": color3_list,\n",
    "    \"Brightness\": brightness_list\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{user_id}_image_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547b772",
   "metadata": {},
   "source": [
    "### Merge the data together and form into one final csv file for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b605d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging colors and brightness to the user file\n",
    "\n",
    "# Read in the csv files\n",
    "df_ratings = pd.read_csv(f'{user_id}_ratings.csv')\n",
    "df_colors = pd.read_csv(f\"{user_id}_image_analysis.csv\")\n",
    "\n",
    "# Merge the two dataframes on the common column\n",
    "merged_df = pd.merge(df_ratings, df_colors, on='Img_File_Name')\n",
    "\n",
    "colors_columns = ['Color1', 'Color2', 'Color3', 'Brightness']\n",
    "ratings_columns = [\"UserID\",\n",
    "     \"Title\",\n",
    "     \"Img_Path\",\n",
    "     \"Img_File_Name\",\n",
    "     \"Year\",\n",
    "     \"Description\",\n",
    "     \"Directors\",\n",
    "     \"Stars\",\n",
    "     \"Viewer_Advisory\",\n",
    "     \"Duration\",\n",
    "     \"Genre\",\n",
    "     \"Votes\",\n",
    "     \"Movie_Rating\",\n",
    "     \"User_Rating\"]\n",
    "\n",
    "final_merged = merged_df[ratings_columns + colors_columns]\n",
    "\n",
    "# Select the columns you want to keep and save to a new file\n",
    "#merged_df = merged_df[['Img_File_Name', 'Color1', 'Color2', 'Color3', 'Brightness']]\n",
    "final_merged.to_csv(f'{user_id}_img_ratings.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf6755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
