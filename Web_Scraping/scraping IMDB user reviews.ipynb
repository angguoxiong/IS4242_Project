{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data required in lists\n",
    "users_list = ['ur117926588', 'ur15298231', 'ur1994077', 'ur17646017', 'ur4532636', 'ur22171966']\n",
    "user_id = []\n",
    "movie_title_list = []\n",
    "year_list = []\n",
    "review_title_list = []\n",
    "review_list = []\n",
    "error_msg = []\n",
    "review_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [05:26<00:00,  6.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1254/1254 [00:25<00:00, 50.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 87/87 [19:18<00:00, 13.32s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2186/2186 [00:53<00:00, 40.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [23:15<00:00, 14.24s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2464/2464 [00:57<00:00, 42.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [02:48<00:00,  2.41s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1753/1753 [00:36<00:00, 47.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [16:20<00:00,  7.91s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3103/3103 [00:50<00:00, 61.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for User 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [10:46<00:00,  8.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2010/2010 [00:30<00:00, 66.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for user in range(len(users_list)):\n",
    "    print(\"Scraping for User {}\".format(user+1))\n",
    "#     driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    url = 'https://www.imdb.com/user/{}/reviews'.format(users_list[user])\n",
    "    time.sleep(1)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    sel = Selector(text = driver.page_source)\n",
    "    num_of_reviews = sel.css(\".header span::text\").extract_first().replace(',','').split(' ')[0]\n",
    "    more_review_pages = int(int(num_of_reviews)/25)\n",
    "    \n",
    "    user_id += [users_list[user] for i in range(int(num_of_reviews))]\n",
    "    \n",
    "    # Loading all the reviews in the single page before scraping\n",
    "    for i in tqdm(range(more_review_pages)):\n",
    "        try:\n",
    "            css_selector = 'load-more-trigger'\n",
    "            driver.find_element(By.ID, css_selector).click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "    for r in tqdm(reviews):\n",
    "        try:\n",
    "            sel2 = Selector(text = r.get_attribute('innerHTML'))\n",
    "            try:\n",
    "                movie_title = sel2.css('.lister-item-header a::text').extract_first().strip()\n",
    "            except:\n",
    "                movie_title = np.NaN\n",
    "            try:\n",
    "                year = sel2.css('.lister-item-year.text-muted.unbold::text').extract_first().strip().replace('(','').replace(')','')\n",
    "                year = re.sub(r'[a-zA-Z\\s]+', '', year)\n",
    "            except:\n",
    "                year = np.NaN\n",
    "            try:\n",
    "                review_title = sel2.css('.title::text').extract_first().strip()\n",
    "            except:\n",
    "                review_title = np.NaN\n",
    "            try:\n",
    "                # extract all paragraphs inside review\n",
    "                review = sel2.css('.text.show-more__control::text').extract()\n",
    "                review = ' '.join(review)\n",
    "            except:\n",
    "                review = np.NaN\n",
    "                \n",
    "            movie_title_list.append(movie_title)\n",
    "            year_list.append(year)\n",
    "            review_title_list.append(review_title)\n",
    "            review_list.append(review)\n",
    "        except Exception as e:\n",
    "            error_msg.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all data in dataframe\n",
    "reviews_df = pd.DataFrame({\n",
    "    \"UserID\": user_id,\n",
    "    \"Title\": movie_title_list,\n",
    "    \"Year\": year_list,\n",
    "    \"Review_Title\": review_title_list,\n",
    "    \"Review\": review_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset\n",
    "reviews_df.to_csv(path_or_buf = \"users_reviews.csv\"\n",
    "                          , index = False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
